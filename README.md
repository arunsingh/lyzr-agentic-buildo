
## Agentic Orchestration Builder — Monorepo

Reimagined n8n for agentic, event‑driven workflows. Supports deterministic DAGs and adaptive agent behavior with policy‑gated edges, human‑in‑the‑loop, replayable state, and observability.

## Access the service (TL;DR)
```bash
# Option A: docker-compose (recommended)
cd docker && docker compose up --build
# API: http://localhost:8000, OPA: http://localhost:8181, Audit: http://localhost:8085

# Option B: single API container
docker build -f docker/Dockerfile.api -t aob-api .
docker run -p 8000:8000 aob-api
# API: http://localhost:8000

# Option C: Helm (Kubernetes)
helm install aob charts/agentic-orch -n aob --create-namespace
kubectl -n aob port-forward deploy/agentic-orch 8000:8000
# API: http://localhost:8000
```

Endpoints (HATEOAS)
- GET `/` → links
- POST `/workflows/compile` → upload YAML
- POST `/workflows/start` → start
- POST `/workflows/resume` → resume with approval
- GET `/workflows/{cid}/events` → event log
- Stubs: `POST /agents`, `POST /invocations`, `POST /sessions`

### Tech stack
- **Language**: Python 3.11
- **API**: FastAPI with OIDC/JWT validation
- **Eventing**: Kafka (dev: in‑memory queue also available)
- **State**: Postgres (dev: in‑memory store also available)
- **Policy**: OPA (Open Policy Agent)
- **Auth**: Keycloak (OIDC/OAuth2), JWT validation with JWKS
- **Observability**: OpenTelemetry (OTLP/HTTP) with distributed tracing
- **Containers/Orchestration**: Docker, Helm, Kubernetes

### Enterprise 3‑layer architecture
```
┌──────────────────────────────────────────────────────────────────────────────┐
│  ③ GENERAL WORKFLOW ENGINE (Graph of Agents)                                 │
│  DAG/graph compiler • SLA/cost-aware routing • HITL gates • decision fusion  │
│  OPA policy on edges • lineage/replay • actuation adapters (tickets/APIs)    │
└──────────────▲───────────────────────────────────────────────────────────────┘
               │  (typed results from agents + tool calls + RAG bundles)
┌──────────────┴───────────────────────────────────────────────────────────────┐
│  ② AGENTS LAYER — Processing • Decision • Interaction units                   │
│  Retrieval/parsing/sim • rules/optimizers/MCDA • chat/UX/HITL • agent mesh   │
│  Standard tool protocol (MCP) • stateful LangGraph-style orchestration        │
└──────────────▲───────────────────────────────────────────────────────────────┘
               │  (APIs: data/models/tools/policy/obs; zero-trust by default)
┌──────────────┴───────────────────────────────────────────────────────────────┐
│  ① CAPABILITIES LAYER (Foundational primitives)                               │
│  Streams/CDC/ETL • Hybrid knowledge fabric (graph + vector + keyword + SQL)   │
│  Model gateway (vLLM/hosted) • Tool registry (MCP servers) • OPA • OTEL       │
│  Platform: K8s + mesh • multi-tenant • GitOps • HA/DR • quotas/FinOps         │
└──────────────────────────────────────────────────────────────────────────────┘
```

### 3‑plane AaaS reference architecture
```
┌────────────────────────────── CONTROL PLANE ────────────────────────────────┐
│ Agent Registry | Versioning | Catalog | Tenancy+RBAC | Policy Mgmt (OPA)   │
│ Eval/Promote   | Pricing/SKUs | API Keys/OAuth | Metering/Billing          │
└───────────────▲─────────────────────────────────────────────────────────────┘
                │ (AgentSpec, PolicyBundle, Tool contracts, Model profiles)
┌───────────────┴──────────────── DATA/POLICY PLANE ─────────────────────────┐
│ RAG bundle store | Vector+Graph+SQL fabric | Secrets/KMS | Audit/Lineage   │
│ Observability (OTel) | Artifact store (models/prompts/skills)              │
└───────────────▲─────────────────────────────────────────────────────────────┘
                │ (Invocation requests, events, tool calls, model IO)
┌───────────────┴──────────────── EXECUTION PLANE ───────────────────────────┐
│ API Gateway → Session Service → Execution Service (Runner Pool: pods/microVM)│
│ Model Gateway (vLLM/hosted) | Tool Gateway (MCP proxy) | HITL Console      │
│ DLQ/Retry/Kafka topics | Memory service | Snapshot/Replayer                │
└────────────────────────────────────────────────────────────────────────────┘
```

## Repository layout
- `packages/agentic_core` – engine, YAML compiler, policies, OTEL, audit
- `packages/agentic_adapters` – Kafka/Postgres adapters
- `services/api` – public API (HATEOAS), compiles/executes workflows
- `services/agent_registry` – AgentSpec CRUD (stub)
- `services/session_service` – sessions/HITL (stub)
- `services/metering_service` – usage counters (stub)
- `services/audit_service` – DecisionRecord ingest (stub)
- `services/worker` – background runners (placeholder)
- `charts/agentic-orch` – Helm chart
- `docker/` – Dockerfiles and docker‑compose
- `policies/` – OPA rego bundles
- `tests/` – sample tests
- `docs/pricing/` – SKU & pricing matrix (markdown + JSON)

## Core concepts
- **AgentSpec v1**: versioned agent package – graph, tools (MCP), policies, model profile, memory.
- **WorkflowSpec (YAML)**: declarative nodes and edges with `policies` on edges.
- **Events**: event‑sourced state (`events` table/stream) with replay.
- **Policy**: OPA decision `data.aob.allow` evaluated per edge.
- **DecisionRecord**: per‑node audit (inputs/outputs/policies/cost/latency).

### Sample WorkflowSpec YAML
```yaml
id: demo
nodes:
  - id: n1; kind: task; name: uppercase; expr: "ctx.bag"
  - id: n2; kind: agent; name: summarize; expr: "ctx.bag"
  - id: n3; kind: human; name: review; approval_key: "approval"
  - id: n4; kind: task; name: ship; expr: "ctx.bag"
edges:
  - from: n2; to: n3; policies: [require_human_for_risk_high]
```

### Sample Rego (policies/aob.rego)
```rego
package aob
default allow = true
deny_no_approval {
  input.edge.policies[_] == "require_human_for_risk_high"
  not input.ctx.bag.approval
}
allow { not deny_no_approval }
```

## Running locally (docker‑compose)
```bash
cd docker
# Reset stack (optional if previously running)
docker compose down -v

# Build and always pull upstream images
docker compose up --pull always --build
```
Services:
- API: `http://localhost:8000`
- OPA: `http://localhost:8181`
- Audit: `http://localhost:8085`
- Agent Registry: `http://localhost:8081`
- Session Service: `http://localhost:8082`
- Metering: `http://localhost:8083`
- Keycloak: `http://localhost:8089` (admin/admin)
- Postgres: `localhost:5432`
  - Note: in compose we map to host port `55432` to avoid conflicts; use DSN `postgres://postgres:postgres@localhost:55432/aob` when connecting from host tools.
- Kafka: `localhost:9092`
- Redis: `localhost:6379`

Notes:
- Kafka/Zookeeper use Confluent images (`confluentinc/cp-kafka:7.6.1`, `confluentinc/cp-zookeeper:7.6.1`). The broker advertises `PLAINTEXT://kafka:9092` inside the compose network and is mapped to `localhost:9092` on the host.
- The outbox worker is enabled and publishes to Kafka when Postgres and Kafka are healthy.

### OIDC with Keycloak (local)
- Compose includes Keycloak at `http://localhost:8089` (admin/admin).
- Create a realm `demo`, a public client `aob-api` with redirect `http://localhost:8000` and audience `aob-api`.
- Obtain a token:
```bash
curl -s -X POST \
  -H 'content-type: application/x-www-form-urlencoded' \
  -d 'grant_type=client_credentials&client_id=aob-api&client_secret=XXXX' \
  http://localhost:8089/realms/demo/protocol/openid-connect/token | jq -r .access_token
```
- Call API with the token:
```bash
curl -H "Authorization: Bearer $TOKEN" http://localhost:8000/
```
- Env vars:
  - `OIDC_ISSUER_URL=http://localhost:8089/realms/demo`
  - `OIDC_AUDIENCE=aob-api`
  - `OIDC_REQUIRED_SCOPES=` (space-delimited)

#### Keycloak Setup Steps
1. Access Keycloak admin console: `http://localhost:8089`
2. Login with `admin/admin`
3. Create realm `demo`:
   - Click "Create realm"
   - Name: `demo`
   - Click "Create"
4. Create client `aob-api`:
   - Go to "Clients" → "Create client"
   - Client ID: `aob-api`
   - Client type: `OpenID Connect`
   - Valid redirect URIs: `http://localhost:8000/*`
   - Click "Save"
5. Configure client settings:
   - Access Type: `public`
   - Standard Flow Enabled: `ON`
   - Direct Access Grants Enabled: `ON`
   - Service Accounts Enabled: `ON`
   - Authorization Enabled: `ON`
   - Click "Save"
6. Create user (optional):
   - Go to "Users" → "Create new user"
   - Username: `testuser`
   - Email: `test@example.com`
   - Click "Save"
   - Go to "Credentials" tab → "Set password"
   - Password: `testpass`
   - Temporary: `OFF`
   - Click "Save"

#### Dependencies
The API service requires these Python packages for OIDC:
- `python-jose[cryptography]>=3.3.0` - JWT validation and JWKS handling
- `httpx>=0.27.0` - Async HTTP client for JWKS fetching

### Auth & tenancy
- API supports both OIDC Bearer tokens (preferred) and `X-API-Key` header (fallback for local dev).
- OIDC tokens are validated against Keycloak JWKS with configurable issuer, audience, and scopes.
- Tenant is derived from token claims (`tenant_id`, `realm`, or issuer realm).
- For production: configure proper OIDC issuer, enforce required scopes, and implement tenant-scoped data access.

### Tool gateway policy enforcement
- All tool calls should pass through `services/tool_gateway` (`POST /call`). OPA is enforced before proxying (deny-by-default model). Edit `policies/aob.rego` to tailor rules.

### OpenAPI & SDKs
- FastAPI exposes the OpenAPI document at `/openapi.json`.
- Local generation example (requires Java and openapi-generator):
```bash
curl -s http://localhost:8000/openapi.json -o /tmp/openapi.json
openapi-generator generate -i /tmp/openapi.json -g python -o ./sdk/python
openapi-generator generate -i /tmp/openapi.json -g typescript-axios -o ./sdk/typescript
```
SDK artifacts can be uploaded via CI; see “CI/CD and deployments”.

### Try it
1) Compile a workflow
```bash
curl -s -X POST localhost:8000/workflows/compile -H 'content-type: application/json' \
  -d '{"yaml":"id: demo\nnodes:\n  - id: n1; kind: task; name: uppercase; expr: \"ctx.bag\"\n  - id: n2; kind: agent; name: summarize; expr: \"ctx.bag\"\n  - id: n3; kind: human; name: review; approval_key: \"approval\"\n  - id: n4; kind: task; name: ship; expr: \"ctx.bag\"\nedges:\n  - from: n2; to: n3; policies: [require_human_for_risk_high]\n"}'
```
2) Start without approval (expect policy gate or human wait)
```bash
curl -s -X POST localhost:8000/workflows/start -H 'content-type: application/json' \
  -d '{"workflow_id":"demo","text":"hello agentic","approval":false}'
```
3) Inspect events
```bash
curl -s localhost:8000/workflows/demo/events | jq
```
4) Approve and resume
```bash
curl -s -X POST localhost:8000/workflows/resume -H 'content-type: application/json' \
  -d '{"workflow_id":"demo","approval":true}'
```

#### With OIDC Authentication
1) Get token from Keycloak:
```bash
TOKEN=$(curl -s -X POST \
  -H 'content-type: application/x-www-form-urlencoded' \
  -d 'grant_type=client_credentials&client_id=aob-api' \
  http://localhost:8089/realms/demo/protocol/openid-connect/token | jq -r .access_token)
```
2) Use token in API calls:
```bash
curl -H "Authorization: Bearer $TOKEN" -H 'content-type: application/json' \
  -d '{"workflow_id":"demo","text":"hello agentic","approval":false}' \
  localhost:8000/workflows/start
```

## Observability (OpenTelemetry)
- OTEL spans are created per node execution with distributed tracing across services.
- Default exporter: OTLP/HTTP. Configure via env vars:
```bash
export OTEL_EXPORTER_OTLP_ENDPOINT=http://localhost:4318
export OTEL_RESOURCE_ATTRIBUTES=service.name=agentic-core
```
- Use any OTLP collector (e.g., OpenTelemetry Collector, Tempo, Jaeger via OTLP).

### Distributed Tracing Spans
The platform creates spans for:
- **API requests**: FastAPI middleware creates root spans for each HTTP request
- **Workflow execution**: Engine creates spans for each node execution
- **Policy evaluation**: OPA calls are traced with decision results
- **Tool/model calls**: Gateway services trace external calls
- **Database operations**: Postgres adapter traces query execution
- **Event publishing**: Kafka bus traces message publishing

### Span Attributes
Each span includes:
- `service.name`: Service identifier (e.g., `aob-api`, `tool-gateway`)
- `workflow.id`: Workflow correlation ID
- `node.id`: Node identifier being executed
- `tenant.id`: Tenant identifier from auth
- `policy.decision`: OPA decision result
- `tool.name`: Tool being called (for tool gateway spans)
- `model.name`: Model being used (for model gateway spans)

### Visualization
Connect to your preferred observability platform:
- **Jaeger**: `http://localhost:16686` (if using Jaeger all-in-one)
- **Grafana Tempo**: Configure Tempo as OTLP receiver
- **Datadog**: Use Datadog OTLP endpoint
- **New Relic**: Use New Relic OTLP endpoint
- **Honeycomb**: Use Honeycomb OTLP endpoint

## Environment variables
- `OTEL_EXPORTER_OTLP_ENDPOINT` (default: none) – OTLP/HTTP endpoint, e.g. `http://localhost:4318`
- `OTEL_RESOURCE_ATTRIBUTES` (default: none) – Resource attributes, e.g. `service.name=agentic-core`
- `OIDC_ISSUER_URL` (default: `http://localhost:8080/realms/demo`) – Keycloak issuer URL
- `OIDC_AUDIENCE` (default: `aob-api`) – Expected JWT audience
- `OIDC_REQUIRED_SCOPES` (default: none) – Space-delimited required scopes
- `AOB_OPA_URL` (optional) – override OPA base URL (default: `http://localhost:8181`)
- `AOB_AUDIT_ENDPOINT` (optional) – DecisionRecord sink (default: `http://localhost:8085/decisions`)
- `AOB_KAFKA_BOOTSTRAP` (optional) – Kafka bootstrap when using `KafkaBus`
- `AOB_POSTGRES_DSN` (optional) – Postgres DSN when using `PostgresEventStore`
- `AOB_REDIS_URL` (optional) – Redis URL for session leases (default `redis://localhost:6379/0`)
- `SNAPSHOT_EVERY` (optional) – create snapshot automatically every k events
- `AOB_KAFKA_BOOTSTRAP` – Kafka bootstrap (compose defaults to `kafka:9092`)
- `AOB_KAFKA_TOPIC` – topic for events (default `aob.events`)

## Policy evaluation (OPA)
- Engine posts to `POST /v1/data/aob/allow` with input:
```json
{
  "input": {
    "node": {"id":"n2","name":"summarize","kind":"AgentNode"},
    "ctx": {"bag": {"approval": false}},
    "policies": ["require_human_for_risk_high"],
    "edge": {"from":"n2","to":"n3","policies":["require_human_for_risk_high"]}
  }
}
```
Return `true`/`{"allow": true}` to admit, otherwise the engine emits a `policy.denied` event.

## Public API (HATEOAS snippets)
- `GET /` → links
- `POST /workflows/compile` → load YAML
- `POST /workflows/start` → start demo workflow
- `POST /workflows/resume` → resume with approval
- `GET /workflows/{cid}/events` → event log
- AaaS stubs:
  - `POST /agents` { spec }
  - `POST /invocations` { agent_id, version, input }
  - `POST /sessions` { agent_id, input }

## Helm (Kubernetes)
```bash
helm install aob charts/agentic-orch -n aob --create-namespace \
  --set image.repository=aob-api --set image.tag=latest
```
Values (`charts/agentic-orch/values.yaml`) include optional sidecars:
- `agentRegistry.*`, `sessionService.*`, `meteringService.*`, `auditService.*`

## Pricing (reference)
- See `docs/pricing/sku_matrix.md` and `docs/pricing/sku_matrix.json` for packaging, meters, and example plans (Starter/Pro/Enterprise). Tailor to your deployment model.

## CI/CD and deployments
- GitHub Container Registry (GHCR) builds
  - On push to `main`, images are built and pushed to `ghcr.io/<OWNER>/...`
  - Workflows: `.github/workflows/build-images.yml`, `.github/workflows/publish-helm.yml`
- Helm chart (OCI)
  - Chart packaged and pushed to `oci://ghcr.io/<OWNER>`
  - Argo CD can pull the OCI chart directly
- Argo CD multi-cluster
  - `deploy/argocd/applicationset.yaml` defines per-cluster app with Helm values
  - Set `GITHUB_OWNER` env in Argo CD controller for OCI repo path
- Cloud overlays
  - `deploy/kustomize/overlays/{aws,azure,gcp}/values.yaml` provide LB annotations

### Security & supply chain in CI
- SBOM: generated via Syft and uploaded as artifact on each push/PR.
- Vulnerability scans: Trivy filesystem scan; SARIF uploaded to Security tab. Optional Snyk scan if `SNYK_TOKEN` is set.
- Image signing: Cosign keyless signs all GHCR images after build; configure repository to require signature verification on pull if desired.

### Required GitHub secrets (recommend OIDC where possible)
- For GHCR: none required (uses `GITHUB_TOKEN`), ensure Packages: write permission enabled
- For cluster deploys via GitHub Actions to cloud (optional):
  - AWS: `AWS_ROLE_TO_ASSUME`, `AWS_REGION` (use OIDC; configure trust for `repo:<owner>/<repo>:ref:refs/heads/main`)
  - Azure: `AZURE_CLIENT_ID`, `AZURE_TENANT_ID`, `AZURE_SUBSCRIPTION_ID` (federated credentials)
  - GCP: `WORKLOAD_IDENTITY_PROVIDER`, `GCP_SERVICE_ACCOUNT` (OIDC), or `GCP_SA_KEY` as fallback

### Argo CD setup
1) Install Argo CD in each cluster
2) Create a repo credential for GHCR OCI if private
3) Apply `deploy/argocd/applicationset.yaml` (tweak cluster/namespace/owner)
4) Sync apps; verify API exposed

## Extending
- Add real Postgres/Kafka by switching to `PostgresEventStore` and `KafkaBus` in your API init.
- Implement `tool-gateway` and `model-gateway` services.
- Harden OPA (bundles, signature verification, fine‑grained policies).

## Troubleshooting
- API not starting: ensure ports `8000/8080/8081/8082/8083/8085/8181/9092/6379/5432` are free.
  - If port 5432 is in use on host, compose maps Postgres to `55432` (container remains `5432`). Update local DSNs accordingly.
- OPA decisions always allow: confirm `policies/aob.rego` is mounted and OPA at `:8181`.
- No spans: set `OTEL_EXPORTER_OTLP_ENDPOINT` to a running collector.
- Events empty: you may be using in‑memory store; switch to Postgres adapter for persistence.
- Kafka pull errors: we use Confluent images; ensure `docker compose pull` succeeds or check network proxy. If you previously used Bitnami tags, run `docker compose down -v` to clear.
- OIDC token validation fails: verify Keycloak is running, realm/client configured correctly, and `OIDC_ISSUER_URL` matches your setup.
- JWKS fetch errors: check network connectivity to Keycloak and verify the issuer URL is correct.
